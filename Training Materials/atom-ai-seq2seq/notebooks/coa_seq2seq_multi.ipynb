{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Division</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Source Account #</th>\n",
       "      <th>Source Level 1</th>\n",
       "      <th>Source Level 2</th>\n",
       "      <th>Source Level 3</th>\n",
       "      <th>Source Account Description</th>\n",
       "      <th>Target Account #</th>\n",
       "      <th>Target Level 1</th>\n",
       "      <th>Target Level 2</th>\n",
       "      <th>Target Level 3</th>\n",
       "      <th>Target Account Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Misc Apparel and Accessories</td>\n",
       "      <td>02-07218</td>\n",
       "      <td>Liabilities</td>\n",
       "      <td>Current Liabilities</td>\n",
       "      <td>Accounts Payable</td>\n",
       "      <td>Rapid Retail</td>\n",
       "      <td>200101</td>\n",
       "      <td>Liabilities</td>\n",
       "      <td>Current Liabilities</td>\n",
       "      <td>Accounts Payable</td>\n",
       "      <td>Accounts Payable - Trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Misc Apparel and Accessories</td>\n",
       "      <td>102351</td>\n",
       "      <td>Assets</td>\n",
       "      <td>Current Assets</td>\n",
       "      <td>Accounts Receivable</td>\n",
       "      <td>Sublicense Receivable</td>\n",
       "      <td>101304</td>\n",
       "      <td>Assets</td>\n",
       "      <td>Current Assets</td>\n",
       "      <td>Accounts Receivable</td>\n",
       "      <td>Accounts Receivable - Sublicense Receivable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Manufacturing</td>\n",
       "      <td>Misc Apparel and Accessories</td>\n",
       "      <td>02-kbsmt001</td>\n",
       "      <td>Liabilities</td>\n",
       "      <td>Current Liabilities</td>\n",
       "      <td>Accounts Payable</td>\n",
       "      <td>SMT Associates Ltd</td>\n",
       "      <td>200101</td>\n",
       "      <td>Liabilities</td>\n",
       "      <td>Current Liabilities</td>\n",
       "      <td>Accounts Payable</td>\n",
       "      <td>Accounts Payable - Trade</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Division                      Industry Source Account #  \\\n",
       "0  Manufacturing  Misc Apparel and Accessories         02-07218   \n",
       "1  Manufacturing  Misc Apparel and Accessories           102351   \n",
       "2  Manufacturing  Misc Apparel and Accessories      02-kbsmt001   \n",
       "\n",
       "  Source Level 1       Source Level 2       Source Level 3  \\\n",
       "0    Liabilities  Current Liabilities     Accounts Payable   \n",
       "1         Assets       Current Assets  Accounts Receivable   \n",
       "2    Liabilities  Current Liabilities     Accounts Payable   \n",
       "\n",
       "  Source Account Description Target Account # Target Level 1  \\\n",
       "0               Rapid Retail           200101    Liabilities   \n",
       "1      Sublicense Receivable           101304         Assets   \n",
       "2         SMT Associates Ltd           200101    Liabilities   \n",
       "\n",
       "        Target Level 2       Target Level 3  \\\n",
       "0  Current Liabilities     Accounts Payable   \n",
       "1       Current Assets  Accounts Receivable   \n",
       "2  Current Liabilities     Accounts Payable   \n",
       "\n",
       "                    Target Account Description  \n",
       "0                     Accounts Payable - Trade  \n",
       "1  Accounts Receivable - Sublicense Receivable  \n",
       "2                     Accounts Payable - Trade  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = 'C:/Users/devquinn/OneDrive - Deloitte (O365D)/Desktop/atom-dc-coa/dc-atom-coa/project/data/BS/'\n",
    "files = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J']\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for letter in files:\n",
    "    file_name = 'Company'+letter+'.xlsx'\n",
    "    df_company = pd.read_excel(data_path+file_name, dtype=str, sheet_name='Sheet1', header=0)\n",
    "    df = pd.concat([df, df_company])\n",
    "\n",
    "#cut to 3 source/target levels\n",
    "df = df.drop(['Target Level 4', 'Source Level 4', 'Source Level 5', 'Source Level 6', 'Source Level 7',\n",
    "              'Source Level 8', 'Source Level 9', 'Source Level 10'], axis=1)\n",
    "#shuffle\n",
    "#df = df.sample(frac=1)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Division                      object\n",
       "Industry                      object\n",
       "Source Account #              object\n",
       "Source Level 1                object\n",
       "Source Level 2                object\n",
       "Source Level 3                object\n",
       "Source Account Description    object\n",
       "Target Account #              object\n",
       "Target Level 1                object\n",
       "Target Level 2                object\n",
       "Target Level 3                object\n",
       "Target Account Description    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "\n",
    "    text = str(text)\n",
    "    text = text.lower().strip()\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation+string.digits])\n",
    "    text = re.sub('\\\\s+', ' ', text)\n",
    "\n",
    "    return text\n",
    "\n",
    "def plot_loss(model_name, losses, n_iters, benchmark_every, learning_rate):\n",
    "    x = np.arange(0, n_iters, benchmark_every)\n",
    "    y = losses\n",
    "    plt.figure()\n",
    "    plt.plot(x, y)\n",
    "    plt.title('Training Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    #current_dir = os.getcwd()\n",
    "    # save_to = os.path.join(current_dir, r'loss_plots')\n",
    "    # if not os.path.exists(save_to): os.makedirs(save_to)\n",
    "    # plt.savefig(os.path.join(save_to, f'loss_{model_name}_{learning_rate}.jpg'))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 19116  \n",
      "Testing size: 3374\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source Level 1</th>\n",
       "      <th>Source Level 2</th>\n",
       "      <th>Source Level 3</th>\n",
       "      <th>Source Account Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1866</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>ircs pchproduction resiting expenses pc ba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5479</th>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>accrual medial fee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>m mars financial statement v full trial balan</td>\n",
       "      <td>non corporate accounts</td>\n",
       "      <td>balance sheet</td>\n",
       "      <td>legal memo account for fiscal losses credit</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Source Level 1          Source Level 2  \\\n",
       "1866                                            nan                     nan   \n",
       "5479                                            nan                     nan   \n",
       "1222  m mars financial statement v full trial balan  non corporate accounts   \n",
       "\n",
       "     Source Level 3                   Source Account Description  \n",
       "1866            nan   ircs pchproduction resiting expenses pc ba  \n",
       "5479            nan                           accrual medial fee  \n",
       "1222  balance sheet  legal memo account for fiscal losses credit  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_data = df.iloc[:, 3:7].copy()\n",
    "for col in source_data.columns:\n",
    "    source_data[col] = source_data[col].apply(preprocess_text)\n",
    "\n",
    "target_data = df.iloc[:, 8:].copy()\n",
    "for col in target_data.columns:\n",
    "    target_data[col] = target_data[col].apply(preprocess_text)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(source_data, target_data, test_size=0.15, shuffle=True, random_state=10)\n",
    "print(f'Training size: {len(x_train)}  \\nTesting size: {len(x_test)}')\n",
    "x_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Vocabulary:\n",
    "\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2: \"UNKNOWN\"}\n",
    "        self.n_words = 3  # Count SOS, EOS, UNKNOWN\n",
    "\n",
    "    def add_sentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.add_word(word)\n",
    "\n",
    "    def add_word(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pairs(x_data, y_data):\n",
    "\n",
    "    x_data = x_data.reset_index(drop=True)\n",
    "    y_data = y_data.reset_index(drop=True)\n",
    "\n",
    "    sources, targets = [], []\n",
    "    \n",
    "    for i in range(len(x_data)):\n",
    "        source_level_text, target_level_text = [], []\n",
    "\n",
    "        for col in x_data:\n",
    "            s_text = x_data.loc[i, col]\n",
    "            source_level_text.append(s_text)\n",
    "        for col in y_data:\n",
    "            t_text = y_data.loc[i, col]\n",
    "            target_level_text.append(t_text)\n",
    "\n",
    "        sources.append(source_level_text)\n",
    "        targets.append(target_level_text)\n",
    "\n",
    "    pairs = list((zip(sources, targets)))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "def create_vocabulary(set1, set2, x_data, y_data):\n",
    "    \n",
    "    input_set = Vocabulary(set1)\n",
    "    output_set = Vocabulary(set2)\n",
    "    pairs = create_pairs(x_data, y_data)\n",
    "\n",
    "    for pair in pairs:\n",
    "        full_source_string = \" \".join(pair[0])\n",
    "        full_target_string = \" \".join(pair[1])\n",
    "        input_set.add_sentence(full_source_string)\n",
    "        output_set.add_sentence(full_target_string)\n",
    "\n",
    "    return input_set, output_set, pairs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['nan', 'nan', 'nan', 'ircs pchproduction resiting expenses pc ba'],\n",
       " ['nan', 'nan', 'nan', 'eqty clr acct tax'])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_set, output_set, pairs = create_vocabulary('legacy', 'new', x_train, y_train)\n",
    "pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [7],\n",
       "         [8],\n",
       "         [9],\n",
       "         [1]]),\n",
       " tensor([[4],\n",
       "         [5],\n",
       "         [6],\n",
       "         [7],\n",
       "         [1]]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def indexes_from_sentence(set, sentence):\n",
    "    sentence_indexes = []\n",
    "    for word in sentence.split(' '):\n",
    "        if word not in set.word2index:\n",
    "            sentence_indexes.append(2)\n",
    "        else:\n",
    "            sentence_indexes.append(set.word2index[word])\n",
    "            \n",
    "    return sentence_indexes\n",
    "\n",
    "def tensor_from_sentence(set, sentence):\n",
    "    indexes = indexes_from_sentence(set, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "def tensors_from_text_list(text_list, input_set, output_set):\n",
    "    tensors = []\n",
    "    for level in text_list:\n",
    "        print(level)\n",
    "        tensor = tensor_from_sentence(input_set, level)\n",
    "        tensors.append(tensor)\n",
    "        \n",
    "    return tensors\n",
    "\n",
    "def tensors_from_pair(pair, input_set, output_set):\n",
    "    source = pair[0]\n",
    "    target = pair[1]\n",
    "    source_target_pairwise_tensors = []\n",
    "\n",
    "    for i in range(len(source)):\n",
    "        source_level = source[i]\n",
    "        target_level = target[i]\n",
    "        source_level_tensor = tensor_from_sentence(input_set, source_level)\n",
    "        target_level_tensor = tensor_from_sentence(output_set, target_level)\n",
    "        source_target_pairwise_tensors.append((source_level_tensor, target_level_tensor))\n",
    "\n",
    "    return source_target_pairwise_tensors\n",
    "\n",
    "tensors_from_pair(pairs[0], input_set, output_set)[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.name = 'Decoder'\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "\n",
    "class AttnDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=100):\n",
    "        super(AttnDecoder, self).__init__()\n",
    "        self.name = 'AttnDecoder'\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "        attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L1_loss, L2_loss, L3_loss, L4_loss = 0, 1, 2, 3\n",
    "L2_loss += 5\n",
    "level_losses = [L1_loss, L2_loss, L3_loss, L4_loss]\n",
    "level_losses[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_iter(tensors_pair, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=100, teacher_forcing_ratio=0.0):\n",
    "\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    L1_loss, L2_loss, L3_loss, L4_loss = 0, 0, 0, 0\n",
    "    level_losses = [L1_loss, L2_loss, L3_loss, L4_loss]\n",
    "    target_lengths = []\n",
    "\n",
    "    for i in range(len(tensors_pair)):\n",
    "        source_level_tensor = tensors_pair[i][0]\n",
    "        target_level_tensor = tensors_pair[i][1]\n",
    "        source_level_length = source_level_tensor.size(0)\n",
    "        target_level_length = target_level_tensor.size(0)\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        #loop through each word of the source level\n",
    "        for en in range(source_level_length):\n",
    "            encoder_output, encoder_hidden = encoder(source_level_tensor[en], encoder_hidden)\n",
    "            encoder_outputs[en] = encoder_output[0, 0]\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "\n",
    "        use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "        if use_teacher_forcing:\n",
    "            # Teacher forcing: Feed the target as the next input\n",
    "            for de in range(target_level_length):\n",
    "                if(decoder.name == 'AttnDecoder'):\n",
    "                    decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                        decoder_input, decoder_hidden, encoder_outputs)\n",
    "                else:\n",
    "                    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "                \n",
    "                level_losses[i] += criterion(decoder_output, target_level_tensor[de])\n",
    "                decoder_input = target_level_tensor[de]  # Teacher forcing\n",
    "\n",
    "        else:\n",
    "            # Without teacher forcing: use its own predictions as the next input\n",
    "            for de in range(target_level_length):\n",
    "                if(decoder.name == 'AttnDecoder'):\n",
    "                    decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                        decoder_input, decoder_hidden, encoder_outputs)\n",
    "                else:\n",
    "                    decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "\n",
    "                topv, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "                level_losses[i] += criterion(decoder_output, target_level_tensor[de])\n",
    "                if decoder_input.item() == EOS_token:\n",
    "                    break\n",
    "            \n",
    "        level_losses[i].backward(retain_graph=True)\n",
    "        target_lengths.append(target_level_length)\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    total_target_length = np.sum(target_lengths)\n",
    "    loss = 0\n",
    "    for level_loss in level_losses:\n",
    "        loss += level_loss.item()\n",
    "\n",
    "    return loss / total_target_length\n",
    "\n",
    "\n",
    "def train_model(input_set, output_set, encoder, decoder, pairs, n_iters, save_path, model_name, hidden_size, dropout=None, attention=False, benchmark_every=100, save_every=100, learning_rate=0.01,\n",
    "                tf_ratio=0.0, max_length=100, verbose=False):\n",
    "    \n",
    "    if (save_every > n_iters) or (benchmark_every > n_iters):\n",
    "        raise ValueError('Parameter num_iters must be larger than paramters save_every and benchmark_loss_every')\n",
    "    if n_iters % benchmark_every != 0:\n",
    "        raise ValueError('Parameter num_iters must be evenly divisible by parameter benchmark_loss_every')\n",
    "\n",
    "    if(verbose): print(f'\\ntraining model...')\n",
    "    loss_total = 0  # Reset every benchmark_every\n",
    "    losses = []\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    #create training pairs randomly from given list of pairs\n",
    "    training_pairs = [tensors_from_pair(random.choice(pairs), input_set, output_set) for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    #run iteration for each training pair\n",
    "    for i in tqdm(range(1, n_iters + 1)):\n",
    "        tensors_pair = training_pairs[i - 1]\n",
    "\n",
    "        loss = run_iter(tensors_pair, encoder, decoder, encoder_optimizer, decoder_optimizer, \n",
    "                        criterion, max_length=max_length, teacher_forcing_ratio=tf_ratio)\n",
    "        \n",
    "        loss_total += loss\n",
    "        #record loss\n",
    "        if i % benchmark_every == 0:\n",
    "            loss_avg = loss_total / benchmark_every\n",
    "            losses.append(loss_avg)\n",
    "            loss_total = 0\n",
    "        #save model parameters\n",
    "        if i % save_every == 0:\n",
    "            torch.save({'en_sd': encoder.state_dict(),\n",
    "                        'de_sd': decoder.state_dict(),\n",
    "                        'en_opt': encoder_optimizer,\n",
    "                        'de_opt': decoder_optimizer,\n",
    "                        'en_opt_sd': encoder_optimizer.state_dict(),\n",
    "                        'de_opt_sd': decoder_optimizer.state_dict(),\n",
    "                        'loss': losses[-1],\n",
    "                        'input_dict': input_set.__dict__,\n",
    "                        'output_dict': output_set.__dict__,\n",
    "                        'hidden_size': hidden_size,\n",
    "                        'dropout': dropout, \n",
    "                        'max_length': max_length,\n",
    "                        'attention': attention,\n",
    "                        }, os.path.join(save_path, f'{model_name}_{i}_{losses[-1]:.3f}.hdf5'))\n",
    "\n",
    "    plot_loss(model_name, losses, n_iters, benchmark_every, learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [11:43<00:00,  2.84it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoder = Encoder(input_set.n_words, 256).to(device)\n",
    "decoder = Decoder(256, output_set.n_words).to(device)\n",
    "\n",
    "save_path = os.getcwd()\n",
    "\n",
    "train_model(input_set, output_set, encoder, decoder, pairs, n_iters=2000, save_path=save_path, model_name='model1',\n",
    "            hidden_size=256, dropout=None, attention=False, save_every = 2000, benchmark_every=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "559d1aecbf8f97047d84863de8a860628de5e493631dd3e19f1951ec99c0a7ae"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
